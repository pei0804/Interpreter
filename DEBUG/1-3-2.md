```go
*github.com/pei0804/interpreter/lexer.Lexer {
        input: "let five = 5;\nlet ten = 10;\n\nlet add = fn(x, y) {\n
 x + y;\n};\n\nl...+28 more",
        position: 0,
        readPosition: 1,
        ch: 108,}
(dlv) p len(l.input)
92

// 最初のletの解釈
> github.com/pei0804/interpreter/lexer.(*Lexer).NextToken() ./lexer.go:
44 (PC: 0x10f1d29)
    39:
    40: // NextToken 現在の位置にある文字をトークンに変換する 空白は無
視する
    41: func (l *Lexer) NextToken() token.Token {
    42:         var tok token.Token
    43:
=>  44:         l.skipWhitespace()
    45:
    46:         switch l.ch {
    47:         case '=':
    48:                 tok = newToken(token.ASSIGN, l.ch)
    49:         case ';':
(dlv) s

// letの前には空白がないので、readCharは発火しない
> github.com/pei0804/interpreter/lexer.(*Lexer).skipWhitespace() ./lexe
r.go:108 (PC: 0x10f25cf)
   103:
   104: func isDigit(ch byte) bool {
   105:         return '0' <= ch && ch <= '9'
   106: }
   107:
=> 108: func (l *Lexer) skipWhitespace() {
   109:         for l.ch == ' ' || l.ch == '\t' || l.ch == '\n' || l.ch
 == '\r' {
   110:                 l.readChar()
   111:         }
   112: }
   113:
(dlv)

// switchの中のどれにも当てはまらないので、文字列用の処理に入る
> github.com/pei0804/interpreter/lexer.(*Lexer).NextToken() ./lexer.go:
68 (PC: 0x10f1e87)
    63:         case 0:
    64:                 tok.Literal = ""
    65:                 tok.Type = token.EOF
    66:         default:
    67:                 if isLetter(l.ch) {
=>  68:                         tok.Literal = l.readIdentifier()
    69:                         tok.Type = token.LookupIdent(tok.Litera
l)
    70:                         return tok
    71:                 } else if isDigit(l.ch) {
    72:                         tok.Type = token.INT
    73:                         tok.Literal = l.readNumber()
(dlv)

// readIdentifier() で文字列が終了するまでループする
> github.com/pei0804/interpreter/lexer.(*Lexer).readIdentifier() ./lexe
r.go:85 (PC: 0x10f2393)
    80:         return tok
    81: }
    82:
    83: func (l *Lexer) readIdentifier() string {
    84:         position := l.position
=>  85:         for isLetter(l.ch) {
    86:                 l.readChar()
    87:         }
    88:         return l.input[position:l.position]
    89: }
    90:

// letの次の空白まで来たらループを抜ける
// isLetterが許可している文字列は
// return 'a' <= ch && ch <= 'z' || 'A' <= ch && ch <= 'Z' || ch == '_'
> github.com/pei0804/interpreter/lexer.(*Lexer).readIdentifier() ./lexer.go:88 (PC: 0
x10f23c9)
    83: func (l *Lexer) readIdentifier() string {
    84:         position := l.position
    85:         for isLetter(l.ch) {
    86:                 l.readChar()
=>  87:         }
    88:         return l.input[position:l.position]
    89: }
    90:

// 特殊な意味のある文字列か調べる
> github.com/pei0804/interpreter/lexer.(*Lexer).NextToken() ./lexer.go:69 (PC: 0x10f1
ebc)
    64:                 tok.Literal = ""
    65:                 tok.Type = token.EOF
    66:         default:
    67:                 if isLetter(l.ch) {
    68:                         tok.Literal = l.readIdentifier()
=>  69:                         tok.Type = token.LookupIdent(tok.Literal)
    70:                         return tok
    71:                 } else if isDigit(l.ch) {
    72:                         tok.Type = token.INT
    73:                         tok.Literal = l.readNumber()
    74:                         return tok
(dlv)

> github.com/pei0804/interpreter/token.LookupIdent() /Users/jumpei/go/src/github.com/
pei0804/interpreter/token/token.go:54 (PC: 0x10f01d3)
    49:         "fn":  FUNCTION,
    50:         "let": LET,
    51: }
    52:
    53: // LookupIdent 特別な意味をもった文字列かチェックする
=>  54: func LookupIdent(ident string) TokenType {
    55:         if tok, ok := keywords[ident]; ok {
    56:                 return tok
    57:         }
    58:         return IDENT
    59: }
(dlv)

> github.com/pei0804/interpreter/token.LookupIdent() /Users/jumpei/go/src/github.com/
pei0804/interpreter/token/token.go:56 (PC: 0x10f0226)
    51: }
    52:
    53: // LookupIdent 特別な意味をもった文字列かチェックする
    54: func LookupIdent(ident string) TokenType {
    55:         if tok, ok := keywords[ident]; ok {
=>  56:                 return tok
    57:         }
    58:         return IDENT
    59: }
(dlv) p keywords[ident]
"LET"

// letという文字列が、Type letであることがわかる
> github.com/pei0804/interpreter/lexer.TestNextToken() ./lexer_test.go:70 (PC: 0x10f2
a73)
    65:
    66:         for i, tt := range tests {
    67:                 tok := l.NextToken()
    68:                 log.Printf("Literal: %s Type: %s", tok.Literal, tok.Type)
    69:
=>  70:                 if tok.Type != tt.expectedType {
    71:                         t.Fatalf("tests[%d] - tokentype wrong. expected=%q, g
ot=%q",
    72:                                 i, tt.expectedType, tok.Type)
    73:                 }
    74:
    75:                 if tok.Literal != tt.expectedLiteral {
(dlv) p tok
github.com/pei0804/interpreter/token.Token {Type: "LET", Literal: "let"}

// letの次は空白なのでスキップする
> github.com/pei0804/interpreter/lexer.(*Lexer).skipWhitespace() ./lexer.go:110 (PC:
0x10f25f2)
   105:         return '0' <= ch && ch <= '9'
   106: }
   107:
   108: func (l *Lexer) skipWhitespace() {
   109:         for l.ch == ' ' || l.ch == '\t' || l.ch == '\n' || l.ch == '\r' {
=> 110:                 l.readChar()
   111:         }
   112: }
   113:
   114: func newToken(tokenType token.TokenType, ch byte) token.Token {
   115:         return token.Token{Type: tokenType, Literal: string(ch)}
```
